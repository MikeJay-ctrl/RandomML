{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Layer convnet tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"../data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My data looks like:\n",
      "\n",
      " Training images: 55000\n",
      " Training labels: 55000 \n",
      " Test images: 10000\n",
      " Test labels: 10000\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print(\"My data looks like:\\n\")\n",
    "print(\" Training images: {}\\n Training labels: {} \".format(len(data.train.images), len(data.train.labels)))\n",
    "print(\" Test images: {}\\n Test labels: {}\".format(len(data.test.images), len(data.test.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABpCAYAAAAqXNiiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSESoQBcRiQgV6CIiEaECXUQkIv4fvuDabxBHngYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11883f518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise a few examples\n",
    "samples = np.random.randint(55000, size=(5))\n",
    "\n",
    "for ind, sample in enumerate(samples):\n",
    "    image = data.train.images[sample].reshape(28, 28)\n",
    "    labelVal = np.argmax(data.train.labels[sample], axis=0)\n",
    "    label = \"Label \" + str(labelVal)\n",
    "    plt.subplot(1, 5, ind+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of training images:  (55000, 784)\n",
      "dimensions of test images:  (10000, 784)\n",
      "reshape.. \n",
      "dimensions of training images:  (55000, 28, 28)\n",
      "dimensions of training images:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#images are wrong shape for cnn so need to be shaped in order to retain spacial information\n",
    "print(\"dimensions of training images: \", data.train.images.shape)\n",
    "print(\"dimensions of test images: \", data.test.images.shape)\n",
    "print(\"reshape.. \")\n",
    "train_images = data.train.images.reshape(55000, 28, 28)\n",
    "test_images = data.test.images.reshape(10000, 28, 28)\n",
    "print(\"dimensions of training images: \", train_images.shape)\n",
    "print(\"dimensions of training images: \", test_images.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "# create actual numeric versions of label data\n",
    "print(data.train.labels.shape)\n",
    "train_label_cls = np.argmax(data.train.labels, axis=0)\n",
    "test_label_cls = np.array([label.argmax() for label in data.test.labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_1:0' shape=(?, 14, 14, 32) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#create TF Placeholders\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "y_class = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "#create TF Variables\n",
    "\n",
    "#conv layers\n",
    "c1 = tf.get_variable('c1', [5, 5, 1 , 16])\n",
    "c1b = tf.get_variable('cb1', [16])\n",
    "\n",
    "c2 = tf.get_variable('c2', [5, 5, 16, 32])\n",
    "c2b = tf.get_variable('cb2', [32])\n",
    "\n",
    "#batchnorm\n",
    "bn_gamma = tf.get_variable('bn_gamma', shape=[16])\n",
    "bn_beta = tf.get_variable('bn_beta', shape=[16])\n",
    "\n",
    "\n",
    "#affine\n",
    "affine1 = tf.get_variable('affine1', [(14 * 14* 32) , 100])\n",
    "a1b = tf.get_variable('a1b', [100])\n",
    "affine2 = tf.get_variable('affine2', [100, 10])\n",
    "a2b = tf.get_variable('a2b', [10])\n",
    "\n",
    "\n",
    "## define comp graph\n",
    "x_img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "c1_out = tf.nn.conv2d(x_img, c1, strides=[1,1,1,1], padding='SAME') + c1b\n",
    "c1_out = tf.nn.relu(c1_out)\n",
    "c1_pool = tf.layers.max_pooling2d(inputs=c1_out, pool_size=[2, 2], strides=2)\n",
    "\n",
    "c2_out = tf.nn.conv2d(c1_pool, c2, strides=[1, 1, 1, 1], padding='SAME') + c2b\n",
    "c2_out = tf.nn.relu(c2_out)\n",
    "c2_flat = tf.reshape(c2_out, [-1, (14 * 14* 32) ])\n",
    "print(c2_out.get_shape)\n",
    "a1_out = tf.matmul(c2_flat, affine1) + a1b\n",
    "logits = tf.matmul(a1_out, affine2) + a2b\n",
    "print(logits.get_shape)\n",
    "# loss and cost\n",
    "predictions = tf.nn.softmax(logits)\n",
    "predicted_class = tf.argmax(predictions, axis=1)\n",
    "\n",
    "total_loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=5e-4).minimize(mean_loss)\n",
    "\n",
    "#have TF compute accuracy\n",
    "correct_prediction = tf.equal(predicted_class, y_class)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for session run\n",
    "session = tf.Session()\n",
    "\n",
    "#init variables\n",
    "session.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_its):\n",
    "    for i in range(num_its):\n",
    "        x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "        training_feed_dict = {x: x_batch, y: y_batch}\n",
    "        session.run(optimizer, training_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 98.6%\n"
     ]
    }
   ],
   "source": [
    "test_feed_dict = {x: data.test.images, y: data.test.labels, y_class: test_label_cls}\n",
    "acc = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "print(\"test set accuracy is {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
